{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch as pt\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check device\n",
    "device = torch.device(\n",
    "    \"cuda:{}\".format(0) if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HCP Data using Simeon preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From DBGDGM code\n",
    "\n",
    "def create_fc_matrices(scan, window_size=30, step_size=10):\n",
    "    \"\"\"\n",
    "    Create functional connectivity matrices using a sliding window approach.\n",
    "    Function from DBGDGM code.\n",
    "    \"\"\"\n",
    "    n_timepoints = scan.shape[1]\n",
    "    fc_matrices = []\n",
    "\n",
    "    for start in range(0, n_timepoints - window_size + 1, step_size):\n",
    "        window = scan[:, start:start + window_size]\n",
    "        correlation_matrix = np.corrcoef(window)   # pearson correlation \n",
    "        fc_matrices.append(correlation_matrix)\n",
    "\n",
    "    return fc_matrices\n",
    "\n",
    "\n",
    "def threshold_fc_matrix(fc_matrix, percentile=5):\n",
    "    \"\"\"\n",
    "    Threshold the FC matrix to keep only the top percentile connections.\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(fc_matrix[np.tril_indices_from(fc_matrix, k=-1)], 100 - percentile)   \n",
    "    graph = (fc_matrix > threshold).astype(int)\n",
    "    np.fill_diagonal(graph, 0)  # remove self-edges\n",
    "    return graph\n",
    "\n",
    "\n",
    "def create_networkx_graph(matrix):\n",
    "    G = nx.Graph(matrix)\n",
    "    return G\n",
    "\n",
    "\n",
    "def convert_to_pyg_graph(nx_graph, label):\n",
    "    graph = nx.Graph(nx_graph)\n",
    "    edges = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(np.identity(graph.number_of_nodes()), dtype=torch.float)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edges, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From DBGDSL code\n",
    "\n",
    "def create_fc_matrices_dbgsl(scan, window_size=30, step_size=10):\n",
    "    \"\"\"\n",
    "    Create functional connectivity matrices using a sliding window approach.\n",
    "    Function created using DBGSL code to split data into windows.\n",
    "    \"\"\"\n",
    "    n_timepoints = scan.shape[1]\n",
    "    t_repetition = (n_timepoints - 2*(window_size - 1) - 1)//(step_size + 1)\n",
    "    fc_matrices = []\n",
    "\n",
    "    for t in range(t_repetition):\n",
    "        window = scan[:, t*step_size:t*step_size+window_size]\n",
    "        correlation_matrix = (np.corrcoef(window) + 1) / 2   # normalized pearson correlation \n",
    "        fc_matrices.append(correlation_matrix)\n",
    "\n",
    "    return fc_matrices\n",
    "\n",
    "def get_x_split(x: pt.Tensor, stride, len_window, t_repetition) -> pt.Tensor:\n",
    "    x_split = pt.stack([x[:, :, t*stride:t*stride+len_window] for t in range(t_repetition)], 1)\n",
    "    return x_split.float()\n",
    "\n",
    "def get_node_features(x_split: pt.Tensor) -> pt.Tensor:\n",
    "    x_split_avg = pt.mean(x_split, -1, keepdim=True)\n",
    "    x_split_std = pt.std(x_split, -1, keepdim=True)\n",
    "    x_split_cov = pt.matmul(x_split - x_split_avg, pt.transpose(x_split - x_split_avg, 2, 3))\n",
    "    node_features = x_split_cov/pt.matmul(x_split_std, pt.transpose(x_split_std, 2, 3))\n",
    "    return node_features\n",
    "\n",
    "def get_coo(adjacency_matrix: pt.Tensor) -> pt.Tensor:\n",
    "    i = 0\n",
    "    edge_indices = pt.nonzero(adjacency_matrix > 0, as_tuple=False).T\n",
    "    edge_index_batch = pt.clone(edge_indices[1:3, :])\n",
    "    for t in range(len(edge_indices[0])):\n",
    "        if i < edge_indices[0][t]:\n",
    "            i = i + 1\n",
    "            n_nodes = max(edge_indices[1][t-1], edge_indices[2][t-1])+1\n",
    "            edge_index_batch[0][t:] = edge_index_batch[0][t:] + n_nodes\n",
    "            edge_index_batch[1][t:] = edge_index_batch[1][t:] + n_nodes\n",
    "    edge_attr_batch = adjacency_matrix[adjacency_matrix > 0].unsqueeze(-1)\n",
    "    batch = edge_indices[0]\n",
    "    return edge_index_batch, edge_attr_batch, batch\n",
    "\n",
    "\n",
    "def construct_graph(x_ebd: torch.Tensor) -> torch.Tensor:\n",
    "    batch_size = x_ebd.shape[0]\n",
    "    batch_adjacency_matrices = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sample = x_ebd[i]\n",
    "        sample = F.softmax(sample, -1)\n",
    "        adjacency_matrix = torch.matmul(sample, sample.transpose(1, 2))\n",
    "        batch_adjacency_matrices.append(adjacency_matrix)\n",
    "    adjacency_matrix_batch = torch.stack(batch_adjacency_matrices, dim=0)\n",
    "\n",
    "    return adjacency_matrix_batch\n",
    "\n",
    "def sparsify(adjacency_matrix_batch: torch.Tensor) -> torch.Tensor:\n",
    "    threshold = torch.nn.parameter.Parameter(torch.full((1,), -5.0))\n",
    "    batch_sparse_adjacency = []\n",
    "\n",
    "    for i in range(adjacency_matrix_batch.size(0)):\n",
    "        adjacency_matrix = adjacency_matrix_batch[i]\n",
    "        sparse_adjacency = F.relu(adjacency_matrix - torch.sigmoid(threshold))\n",
    "        batch_sparse_adjacency.append(sparse_adjacency)\n",
    "    sparse_adjacency_batch = torch.stack(batch_sparse_adjacency, dim=0)\n",
    "\n",
    "    return sparse_adjacency_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From DBGSL code\n",
    "\n",
    "class InceptionTC(nn.Module):\n",
    "    def __init__(self, itcn_d, dilation):\n",
    "        super(InceptionTC, self).__init__()\n",
    "        self.t_conv_0 = nn.Conv1d(itcn_d, itcn_d//3, kernel_list[0], dilation=dilation, padding=(kernel_list[0]-1)*dilation)\n",
    "        self.t_conv_1 = nn.Conv1d(itcn_d, itcn_d//3, kernel_list[1], dilation=dilation, padding=(kernel_list[1]-1)*dilation)\n",
    "        self.t_conv_2 = nn.Conv1d(itcn_d, itcn_d//3, kernel_list[2], dilation=dilation, padding=(kernel_list[2]-1)*dilation)\n",
    "        self.bn = nn.BatchNorm1d(itcn_d)\n",
    "\n",
    "    def forward(self, x_split, dilation):\n",
    "        x_cat = [\n",
    "            self.clip_end(self.t_conv_0(x_split), 0, dilation),\n",
    "            self.clip_end(self.t_conv_1(x_split), 1, dilation),\n",
    "            self.clip_end(self.t_conv_2(x_split), 2, dilation)\n",
    "        ]\n",
    "        x_cat = torch.cat(x_cat, 1)\n",
    "        x_out = F.relu(self.bn(x_cat))\n",
    "        return x_out\n",
    "\n",
    "    def clip_end(self, x, i, dilation):\n",
    "        padding = (kernel_list[i] - 1) * dilation\n",
    "        x = x[:, :, :-padding].contiguous()\n",
    "        return x\n",
    "\n",
    "\n",
    "class ITCN(nn.Module):\n",
    "    def __init__(self, batch_size, n_neurons, itcn_d, t_repetition, kernel_list):\n",
    "        super(ITCN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.n_neurons = n_neurons\n",
    "        self.itcn_d = itcn_d\n",
    "        self.t_repetition = t_repetition\n",
    "        self.kernel_list = kernel_list\n",
    "        self.inception_tc_2 = InceptionTC(itcn_d, 2)  \n",
    "        self.inception_tc_4 = InceptionTC(itcn_d, 4)\n",
    "        self.inception_tc_6 = InceptionTC(itcn_d, 6)\n",
    "\n",
    "    def forward(self, x_split):\n",
    "        x_split = x_split.reshape(self.batch_size * self.n_neurons, self.itcn_d, self.t_repetition)\n",
    "        x_split = self.inception_tc_2(x_split, 2)\n",
    "        x_split = self.inception_tc_4(x_split, 4)\n",
    "        x_split = self.inception_tc_6(x_split, 6)\n",
    "        x_split = x_split.reshape(self.batch_size, self.t_repetition, self.n_neurons, self.itcn_d)\n",
    "        return x_split\n",
    "\n",
    "\n",
    "class RegionEmbedding(nn.Module):\n",
    "    def __init__(self, len_window, itcn_d, ebd_d, batch_size, n_neurons, t_repetition, kernel_list):\n",
    "        super(RegionEmbedding, self).__init__()\n",
    "        self.input_layer = nn.Linear(len_window, itcn_d)\n",
    "        self.itcn_layer = ITCN(batch_size, n_neurons, itcn_d, t_repetition, kernel_list)\n",
    "        self.output_fc = nn.Sequential(nn.Linear(itcn_d, itcn_d), nn.ReLU(), nn.Linear(itcn_d, ebd_d))\n",
    "\n",
    "    def forward(self, x_split):\n",
    "        x_split = self.input_layer(x_split)\n",
    "        x_split = self.itcn_layer(x_split)\n",
    "        x_split = self.output_fc(x_split)\n",
    "        return x_split\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, n_neurons, tau):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        n_neurons_ebd = int(tau * n_neurons)\n",
    "        self.spatial_attn = nn.Sequential(\n",
    "            nn.Linear(n_neurons, n_neurons_ebd, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons_ebd, n_neurons, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_ebd):\n",
    "        x_spatial_attn = torch.mean(x_ebd, -1)\n",
    "        x_spatial_attn = self.spatial_attn(x_spatial_attn)\n",
    "        x_spatial_attn = x_spatial_attn.unsqueeze(-1)\n",
    "        return x_spatial_attn\n",
    "\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, t_repetition, tau, n_neurons, ebd_d):\n",
    "        super(TemporalAttention, self).__init__()\n",
    "        T_ebd = int(tau * t_repetition)\n",
    "        self.temporal_attn = nn.Sequential(\n",
    "            nn.Linear(t_repetition, T_ebd, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(T_ebd, t_repetition, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_ebd):\n",
    "        x_temporal_attn = x_ebd.view(-1, t_repetition, n_neurons * ebd_d)\n",
    "        x_temporal_attn = torch.mean(x_temporal_attn, -1)\n",
    "        x_temporal_attn = self.temporal_attn(x_temporal_attn)\n",
    "        x_temporal_attn = x_temporal_attn.view(-1, t_repetition, 1, 1)\n",
    "        return x_temporal_attn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, len_window, itcn_d, ebd_d, batch_size, n_neurons, t_repetition, tau, kernel_list):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.region_embd = RegionEmbedding(len_window, itcn_d, ebd_d, batch_size, n_neurons, t_repetition, kernel_list)\n",
    "        self.spat_attention = SpatialAttention(n_neurons, tau)\n",
    "        self.temp_attention = TemporalAttention(t_repetition, tau, n_neurons, ebd_d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ebd = self.region_embd(x)\n",
    "        x_spatial_attention = self.spat_attention(x_ebd)\n",
    "        x_ebd = x_spatial_attention * x_ebd\n",
    "        x_temporal_attn = self.temp_attention(x_ebd)\n",
    "        x_ebd = x_temporal_attn * x_ebd\n",
    "        return x_ebd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similar(p, q):\n",
    "    sim_matrix = p.matmul(q.transpose(-2, -1))\n",
    "    a = torch.norm(p, p=2, dim=-1)\n",
    "    b = torch.norm(q, p=2, dim=-1)\n",
    "    sim_matrix /= a.unsqueeze(-1)\n",
    "    sim_matrix /= b.unsqueeze(-2)\n",
    "    sim_matrix = torch.where(torch.isnan(sim_matrix), torch.full_like(sim_matrix, 0), sim_matrix)\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeMaskingGenerator:\n",
    "    def __init__(self, input_size, mask_ratio):\n",
    "        self.frames, self.num_patches_per_frame = input_size\n",
    "        self.total_patches = self.frames * self.num_patches_per_frame \n",
    "        self.num_masks_per_frame = int(mask_ratio * self.num_patches_per_frame)\n",
    "        self.total_masks = self.frames * self.num_masks_per_frame\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = \"Masks: total patches {}, mask patches {}\".format(\n",
    "            self.total_patches, self.total_masks\n",
    "        )\n",
    "        return repr_str\n",
    "\n",
    "    def __call__(self):\n",
    "        mask_per_frame = np.hstack([\n",
    "            np.zeros(self.num_patches_per_frame - self.num_masks_per_frame),\n",
    "            np.ones(self.num_masks_per_frame),\n",
    "        ])\n",
    "        mask = np.tile(mask_per_frame, (self.frames, 1)).flatten()\n",
    "        return mask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of tensor dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE_PATH:  ../data/hcp/raw/100206_0.npy\n",
      "time_series_data SHAPE:  (360, 490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2733097/983908113.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  fc_matrices_tn = torch.tensor(fc_matrices).reshape(1, len(fc_matrices), 360, 360)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_matrices_tn SHAPE (slicing as in DBGDGM code):  torch.Size([1, 47, 360, 360])\n",
      "fc_matrices_39 SHAPE (slicing as in DBGSL code):  torch.Size([1, 39, 360, 360])\n"
     ]
    }
   ],
   "source": [
    "# ----------- One raw as example -------------------------\n",
    "\n",
    "data_path = '../data/hcp/raw'\n",
    "file_name = '100206_0.npy'\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "print('FILE_PATH: ', file_path)\n",
    "time_series_data = np.load(file_path)[:, :490]\n",
    "print('time_series_data SHAPE: ', time_series_data.shape)\n",
    "label = int(os.path.basename(file_path).split('_')[-1].split('.')[0])\n",
    "\n",
    "fc_matrices = create_fc_matrices(time_series_data) # --> dbgdgm way of slicing the timeseries\n",
    "fc_matrices_tn = torch.tensor(fc_matrices).reshape(1, len(fc_matrices), 360, 360)\n",
    "print('fc_matrices_tn SHAPE (slicing as in DBGDGM code): ', fc_matrices_tn.shape)\n",
    "fc_matrices_dbgsl = create_fc_matrices_dbgsl(time_series_data)\n",
    "fc_matrices_dbgsl_tn = torch.tensor(fc_matrices_dbgsl).reshape(1, len(fc_matrices_dbgsl), 360, 360) # --> dbgsl way of slicing the timeseries\n",
    "print('fc_matrices_39 SHAPE (slicing as in DBGSL code): ', fc_matrices_dbgsl_tn.shape)\n",
    "\n",
    "graphs = [threshold_fc_matrix(fc) for fc in fc_matrices] \n",
    "graph = graphs[0]\n",
    "graph_nx = convert_to_pyg_graph(graph, label)\n",
    "\n",
    "# ----------- One raw as example -------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input size and masking ratio\n",
    "input_size = (490, 360)  # (time points, brain regions)\n",
    "mask_ratio = 0.50\n",
    "\n",
    "# Create a TubeMaskingGenerator instance\n",
    "masking_generator = TubeMaskingGenerator(input_size, mask_ratio)\n",
    "\n",
    "# Generate the tube mask\n",
    "tube_mask = masking_generator()\n",
    "shuffled = np.random.permutation(tube_mask.reshape(time_series_data.T.shape).T)\n",
    "\n",
    "# Apply the tube mask to the data\n",
    "masked_data = time_series_data * shuffled\n",
    "masked_data = masked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_repetition:  39\n",
      "RESHAPING time_series_data:  torch.Size([1, 360, 490])\n",
      "RESHAPING masked_data:  torch.Size([1, 360, 490])\n",
      "SPLITTING WINDOW time_series_data:  torch.Size([1, 39, 360, 30])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1   # remember to change\n",
    "T = 490\n",
    "len_window = 30   \n",
    "stride = 10  \n",
    "t_repetition = (T - 2*(len_window - 1) - 1)//(stride + 1)\n",
    "print('t_repetition: ', t_repetition)\n",
    "\n",
    "# Training hyperparameters\n",
    "device = 'cpu'\n",
    "n_neurons = 360\n",
    "lr = 0.003  # learning rate, 0.003\n",
    "n_itcn_layers = 3\n",
    "n_gru_layers = 1\n",
    "tau = 0.1\n",
    "kernel_list = [3, 5, 7]\n",
    "itcn_d = 9\n",
    "ebd_d = 3\n",
    "gcn_d = 5\n",
    "n_classes = 1\n",
    "\n",
    "time_series_torch = torch.from_numpy(time_series_data).reshape(batch_size, time_series_data.shape[0], time_series_data.shape[1])\n",
    "print('RESHAPING time_series_data: ', time_series_torch.shape)\n",
    "\n",
    "time_series_masked = torch.from_numpy(masked_data).reshape(batch_size, masked_data.shape[0], masked_data.shape[1])\n",
    "print('RESHAPING masked_data: ', time_series_masked.shape)\n",
    "\n",
    "x_split = get_x_split(time_series_masked, stride, len_window, t_repetition)\n",
    "print('SPLITTING WINDOW time_series_data: ', x_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your model\n",
    "model = MyModel(len_window, itcn_d, ebd_d, batch_size, n_neurons, t_repetition, tau, kernel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:33<00:00, 10.70it/s, Loss=0.0137]\n"
     ]
    }
   ],
   "source": [
    "subject = 0\n",
    "n_episodes = 1000   # n_epochs, remember to change\n",
    "save_interval = 50\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_arr = np.zeros(n_episodes)\n",
    "\n",
    "saved = []\n",
    "ground_truth = dataset_ground[subject].float()\n",
    "epochs = trange(n_episodes)\n",
    "for epoch in epochs:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(dataset_input[subject])\n",
    "    adjacency_matrix = construct_graph(outputs)\n",
    "    # sparse_adjacency = sparsify(adjacency_matrix)\n",
    "    loss = criterion(adjacency_matrix, ground_truth)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_arr[epoch] = loss.item()\n",
    "    epochs.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        saved.append(adjacency_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbgdgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
