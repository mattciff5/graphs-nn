{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "\n",
    "# Uncomment below to install required packages. If the CUDA version is not 11.8,\n",
    "# check the https://www.dgl.ai/pages/start.html to find the supported CUDA\n",
    "# version and corresponding command to install DGL.\n",
    "#!pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html > /dev/null\n",
    "#!pip install --upgrade scipy networkx > /dev/null\n",
    "\n",
    "try:\n",
    "    import dgl\n",
    "    installed = True\n",
    "except ImportError:\n",
    "    installed = False\n",
    "print(\"DGL installed!\" if installed else \"Failed to install DGL!\")\n",
    "\n",
    "import dgl\n",
    "import dgl.sparse as dglsp\n",
    "from dgl.data import KarateClubDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/matteoc/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
      "Extracting file to /home/matteoc/.dgl/cora_v2_d697a464\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "(tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
      "         3,  3,  3,  3,  3,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,\n",
      "         7,  7,  8,  8,  8,  8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 13,\n",
      "        13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 20, 21,\n",
      "        21, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 27, 27,\n",
      "        27, 27, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31, 31,\n",
      "        31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33]), tensor([ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  0,  2,\n",
      "         3,  7, 13, 17, 19, 21, 30,  0,  1,  3,  7,  8,  9, 13, 27, 28, 32,  0,\n",
      "         1,  2,  7, 12, 13,  0,  6, 10,  0,  6, 10, 16,  0,  4,  5, 16,  0,  1,\n",
      "         2,  3,  0,  2, 30, 32, 33,  2, 33,  0,  4,  5,  0,  0,  3,  0,  1,  2,\n",
      "         3, 33, 32, 33, 32, 33,  5,  6,  0,  1, 32, 33,  0,  1, 33, 32, 33,  0,\n",
      "         1, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 23, 24, 31, 29, 33,  2, 23,\n",
      "        24, 33,  2, 31, 33, 23, 26, 32, 33,  1,  8, 32, 33,  0, 24, 25, 28, 32,\n",
      "        33,  2,  8, 14, 15, 18, 20, 22, 23, 29, 30, 31, 33,  8,  9, 13, 14, 15,\n",
      "        18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32]))\n",
      "torch.Size([2, 156])\n",
      "34\n",
      "tensor([[0., 1., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 1., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 0.]])\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.sparse as dglsp\n",
    "from dgl.data import KarateClubDataset\n",
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "# Get the graph from DGL's builtin dataset.\n",
    "dataset = KarateClubDataset()\n",
    "dgl_g = dataset[0]\n",
    "\n",
    "dataset_cora = CoraGraphDataset()\n",
    "g = dataset_cora[0]\n",
    "print(g.ndata[\"feat\"])\n",
    "\n",
    "# Get its adjacency matrix.\n",
    "print(dgl_g.edges())\n",
    "indices = torch.stack(dgl_g.edges())\n",
    "print(indices.shape)\n",
    "N = dgl_g.num_nodes()\n",
    "print(N)\n",
    "A = dglsp.spmatrix(indices, torch.ones(indices.shape[1]), (N, N))\n",
    "print(A.to_dense())\n",
    "print(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fc_matrices(scan, window_size=30, step_size=30):\n",
    "    \"\"\"\n",
    "    Create functional connectivity matrices using a sliding window approach.\n",
    "    \"\"\"\n",
    "    n_timepoints = scan.shape[1]\n",
    "    fc_matrices = []\n",
    "\n",
    "    for start in range(0, n_timepoints - window_size + 1, step_size):\n",
    "        window = scan[:, start:start + window_size]\n",
    "        correlation_matrix = np.corrcoef(window)\n",
    "        fc_matrices.append(correlation_matrix)\n",
    "\n",
    "    return fc_matrices\n",
    "\n",
    "\n",
    "def threshold_fc_matrix(fc_matrix, percentile=5):\n",
    "    \"\"\"\n",
    "    Threshold the FC matrix to keep only the top percentile connections.\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(fc_matrix[np.tril_indices_from(fc_matrix, k=-1)], 100 - percentile)   \n",
    "    graph = (fc_matrix > threshold).astype(int)\n",
    "    np.fill_diagonal(graph, 0)  # remove self-edges\n",
    "    return graph\n",
    "\n",
    "\n",
    "def create_networkx_graph(matrix):\n",
    "    G = nx.Graph(matrix)\n",
    "    return G\n",
    "\n",
    "\n",
    "def convert_to_pyg_graph(nx_graph, label):\n",
    "    graph = nx.Graph(nx_graph)\n",
    "    edges = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(np.identity(graph.number_of_nodes()), dtype=torch.float)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edges, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE_PATH:  ../data/hcp/raw/100206_0.npy\n",
      "torch.Size([2, 3231])\n",
      "360\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "CORR_MATRIX:  SparseMatrix(indices=tensor([[  0,   0,   0,  ..., 349, 349, 358],\n",
      "                             [  3,   4,   5,  ..., 358, 359, 359]]),\n",
      "             values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "             shape=(360, 360), nnz=3231)\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as spm\n",
    "\n",
    "data_path = '../data/hcp/raw'\n",
    "file_name = '100206_0.npy'\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "print('FILE_PATH: ', file_path)\n",
    "time_series_data = np.load(file_path)[:, :490]\n",
    "label = int(os.path.basename(file_path).split('_')[-1].split('.')[0])\n",
    "fc_matrices = create_fc_matrices(time_series_data, 490)\n",
    "graphs = [threshold_fc_matrix(fc) for fc in fc_matrices] \n",
    "graph = graphs[0]\n",
    "graph_nx = convert_to_pyg_graph(graph, label)\n",
    "indices = graph_nx.edge_index\n",
    "print(indices.shape)\n",
    "N = graph_nx.num_nodes\n",
    "A = dglsp.spmatrix(indices, torch.ones(indices.shape[1]), (N, N))\n",
    "print(A.to_dense())\n",
    "print('CORR_MATRIX: ', A)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0303, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0333, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0217,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5000, 0.7071],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Compute graph convolution matrix.\n",
    "I = dglsp.identity(A.shape)\n",
    "A_hat = A + I\n",
    "D_hat = dglsp.diag(A_hat.sum(dim=1))\n",
    "D_hat_invsqrt = D_hat ** -0.5\n",
    "A_tilde = D_hat_invsqrt @ A_hat @ D_hat_invsqrt\n",
    "print(A_tilde.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([360])\n"
     ]
    }
   ],
   "source": [
    "# Initial node signals. All nodes except one are set to zero.\n",
    "X = torch.zeros(N)\n",
    "X[0] = 5.\n",
    "print(X.shape)\n",
    "\n",
    "# Number of diffusion steps.\n",
    "r = 8\n",
    "\n",
    "# Record the signals after each diffusion step.\n",
    "results = [X]\n",
    "for _ in range(r):\n",
    "    X = A_tilde @ X\n",
    "    results.append(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# (HIGHLIGHT) Take the advantage of DGL sparse APIs to implement the feature\n",
    "# diffusion in SIGN laconically.\n",
    "################################################################################\n",
    "def sign_diffusion(A, X, r):\n",
    "    # Perform the r-hop diffusion operation.\n",
    "    X_sign = [X]\n",
    "    for i in range(r):\n",
    "        # A^i X\n",
    "        X = A @ X\n",
    "        X_sign.append(X)\n",
    "    return X_sign\n",
    "\n",
    "class SIGN(nn.Module):\n",
    "    def __init__(self, in_size, out_size, r, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.theta = nn.ModuleList(\n",
    "            [nn.Linear(in_size, hidden_size) for _ in range(r + 1)]\n",
    "        )\n",
    "        self.omega = nn.Linear(hidden_size * (r + 1), out_size)\n",
    "\n",
    "    def forward(self, X_sign):\n",
    "        results = []\n",
    "        for i in range(len(X_sign)):\n",
    "            results.append(self.theta[i](X_sign[i]))\n",
    "        Z = F.relu(torch.cat(results, dim=1))\n",
    "        return self.omega(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "def evaluate(g, pred):\n",
    "    label = g.ndata[\"label\"]\n",
    "    val_mask = g.ndata[\"val_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "\n",
    "    # Compute accuracy on validation/test set.\n",
    "    val_acc = (pred[val_mask] == label[val_mask]).float().mean()\n",
    "    test_acc = (pred[test_mask] == label[test_mask]).float().mean()\n",
    "    return val_acc, test_acc\n",
    "\n",
    "\n",
    "def train(model, g, X_sign):\n",
    "    label = g.ndata[\"label\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    optimizer = Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        # Switch the model to training mode.\n",
    "        model.train()\n",
    "\n",
    "        # Forward.\n",
    "        logits = model(X_sign)\n",
    "\n",
    "        # Compute loss with nodes in training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], label[train_mask])\n",
    "\n",
    "        # Backward.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Switch the model to evaluating mode.\n",
    "        model.eval()\n",
    "\n",
    "        # Compute prediction.\n",
    "        logits = model(X_sign)\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Evaluate the prediction.\n",
    "        val_acc, test_acc = evaluate(g, pred)\n",
    "        print(\n",
    "            f\"In epoch {epoch}, loss: {loss:.3f}, val acc: {val_acc:.3f}, test\"\n",
    "            f\" acc: {test_acc:.3f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# If CUDA is available, use GPU to accelerate the training, use CPU\n",
    "# otherwise.\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load graph from the existing dataset.\n",
    "graph = graphs[0]\n",
    "graph_nx = convert_to_pyg_graph(graph, label)\n",
    "indices = graph_nx.edge_index\n",
    "N = graph_nx.num_nodes\n",
    "A = dglsp.spmatrix(indices, torch.ones(indices.shape[1]), (N, N))\n",
    "\n",
    "# Calculate the graph convolution matrix.\n",
    "I = dglsp.identity(A.shape, device=dev)\n",
    "A_hat = A + I\n",
    "D_hat_invsqrt = dglsp.diag(A_hat.sum(dim=1)) ** -0.5\n",
    "A_hat = D_hat_invsqrt @ A_hat @ D_hat_invsqrt\n",
    "\n",
    "# 2-hop diffusion.\n",
    "r = 2\n",
    "X = g.ndata[\"feat\"]\n",
    "X_sign = sign_diffusion(A_hat, X, r)\n",
    "\n",
    "# Create SIGN model.\n",
    "in_size = X.shape[1]\n",
    "out_size = dataset.num_classes\n",
    "model = SIGN(in_size, out_size, r).to(dev)\n",
    "\n",
    "# Kick off training.\n",
    "train(model, g, X_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbgdgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
