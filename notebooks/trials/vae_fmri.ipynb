{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "import time\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check device\n",
    "device = torch.device(\n",
    "    \"cuda:{}\".format(0) if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fc_matrices(scan, window_size=30, step_size=30):\n",
    "    \"\"\"\n",
    "    Create functional connectivity matrices using a sliding window approach.\n",
    "    \"\"\"\n",
    "    n_timepoints = scan.shape[1]\n",
    "    fc_matrices = []\n",
    "\n",
    "    for start in range(0, n_timepoints - window_size + 1, step_size):\n",
    "        window = scan[:, start:start + window_size]\n",
    "        correlation_matrix = np.corrcoef(window)\n",
    "        fc_matrices.append(correlation_matrix)\n",
    "\n",
    "    return fc_matrices\n",
    "\n",
    "\n",
    "def threshold_fc_matrix(fc_matrix, percentile=5):\n",
    "    \"\"\"\n",
    "    Threshold the FC matrix to keep only the top percentile connections.\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(fc_matrix[np.tril_indices_from(fc_matrix, k=-1)], 100 - percentile)   \n",
    "    graph = (fc_matrix > threshold).astype(int)\n",
    "    np.fill_diagonal(graph, 0)  # remove self-edges\n",
    "    return graph\n",
    "\n",
    "\n",
    "def create_networkx_graph(matrix):\n",
    "    G = nx.Graph(matrix)\n",
    "    return G\n",
    "\n",
    "\n",
    "def convert_to_pyg_graph(nx_graph):\n",
    "    graph = nx.Graph(nx_graph)\n",
    "    edges = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(np.identity(graph.number_of_nodes()), dtype=torch.float)\n",
    "    \n",
    "    # For unsupervised learning, you typically don't have node labels\n",
    "    # If you have node features, replace x with them\n",
    "    return Data(x=x, edge_index=edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_index_file(filename):\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "\n",
    "def preprocess_graph(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj_ = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj_.sum(1))\n",
    "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
    "    adj_normalized = (\n",
    "        adj_.dot(degree_mat_inv_sqrt)\n",
    "        .transpose()\n",
    "        .dot(degree_mat_inv_sqrt)\n",
    "        .tocoo()\n",
    "    )\n",
    "    return adj_normalized, sparse_to_tuple(adj_normalized)\n",
    "\n",
    "def load_data(dataset):\n",
    "    # load the data: x, tx, allx, graph\n",
    "    names = [\"x\", \"tx\", \"allx\", \"graph\"]\n",
    "    data_path = \"/home/matteoc/graphs-nn/data/\"\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(data_path+\"data_cora/ind.{}.{}\".format(dataset, names[i]), \"rb\") as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding=\"latin1\"))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "    x, tx, allx, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\n",
    "        data_path+\"data_cora/ind.{}.test.index\".format(dataset)\n",
    "    )\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    if dataset == \"citeseer\":\n",
    "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "        # Find isolated nodes, add them as zero-vecs into the right position\n",
    "        test_idx_range_full = range(\n",
    "            min(test_idx_reorder), max(test_idx_reorder) + 1\n",
    "        )\n",
    "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "        tx_extended[test_idx_range - min(test_idx_range), :] = tx\n",
    "        tx = tx_extended\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "    return adj, features\n",
    "\n",
    "\n",
    "def mask_test_edges(adj):\n",
    "    # Function to build test set with 10% positive links\n",
    "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "    # TODO: Clean up.\n",
    "\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix(\n",
    "        (adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape\n",
    "    )\n",
    "    adj.eliminate_zeros()\n",
    "    # Check that diag is zero:\n",
    "    assert np.diag(adj.todense()).sum() == 0\n",
    "\n",
    "    adj_triu = sp.triu(adj)\n",
    "    adj_tuple = sparse_to_tuple(adj_triu)\n",
    "    edges = adj_tuple[0]\n",
    "    edges_all = sparse_to_tuple(adj)[0]\n",
    "    num_test = int(np.floor(edges.shape[0] / 10.0))\n",
    "    num_val = int(np.floor(edges.shape[0] / 20.0))\n",
    "\n",
    "    all_edge_idx = list(range(edges.shape[0]))\n",
    "    np.random.shuffle(all_edge_idx)\n",
    "    val_edge_idx = all_edge_idx[:num_val]\n",
    "    test_edge_idx = all_edge_idx[num_val : (num_val + num_test)]\n",
    "    test_edges = edges[test_edge_idx]\n",
    "    val_edges = edges[val_edge_idx]\n",
    "    train_edges = np.delete(\n",
    "        edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0\n",
    "    )\n",
    "\n",
    "    def ismember(a, b, tol=5):\n",
    "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
    "        return np.any(rows_close)\n",
    "\n",
    "    test_edges_false = []\n",
    "    while len(test_edges_false) < len(test_edges):\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "        if ismember([idx_i, idx_j], edges_all):\n",
    "            continue\n",
    "        if test_edges_false:\n",
    "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
    "                continue\n",
    "        test_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "    val_edges_false = []\n",
    "    while len(val_edges_false) < len(val_edges):\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "        if ismember([idx_i, idx_j], train_edges):\n",
    "            continue\n",
    "        if ismember([idx_j, idx_i], train_edges):\n",
    "            continue\n",
    "        if ismember([idx_i, idx_j], val_edges):\n",
    "            continue\n",
    "        if ismember([idx_j, idx_i], val_edges):\n",
    "            continue\n",
    "        if val_edges_false:\n",
    "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
    "                continue\n",
    "        val_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "    assert ~ismember(test_edges_false, edges_all)\n",
    "    assert ~ismember(val_edges_false, edges_all)\n",
    "    assert ~ismember(val_edges, train_edges)\n",
    "    assert ~ismember(test_edges, train_edges)\n",
    "    assert ~ismember(val_edges, test_edges)\n",
    "\n",
    "    data = np.ones(train_edges.shape[0])\n",
    "\n",
    "    # Re-build adj matrix\n",
    "    adj_train = sp.csr_matrix(\n",
    "        (data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape\n",
    "    )\n",
    "    adj_train = adj_train + adj_train.T\n",
    "\n",
    "    # NOTE: these edge lists only contain single direction of edge!\n",
    "    return (\n",
    "        adj_train,\n",
    "        train_edges,\n",
    "        val_edges,\n",
    "        val_edges_false,\n",
    "        test_edges,\n",
    "        test_edges_false,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAEModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden1_dim, hidden2_dim):\n",
    "        super(VGAEModel, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "\n",
    "        layers = [\n",
    "            GraphConv(\n",
    "                self.in_dim,\n",
    "                self.hidden1_dim,\n",
    "                activation=F.relu,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "            GraphConv(\n",
    "                self.hidden1_dim,\n",
    "                self.hidden2_dim,\n",
    "                activation=lambda x: x,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "            GraphConv(\n",
    "                self.hidden1_dim,\n",
    "                self.hidden2_dim,\n",
    "                activation=lambda x: x,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "        ]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def encoder(self, g, features):\n",
    "        h = self.layers[0](g, features)\n",
    "        self.mean = self.layers[1](g, h)\n",
    "        self.log_std = self.layers[2](g, h)\n",
    "        gaussian_noise = torch.randn(features.size(0), self.hidden2_dim).to(\n",
    "            device\n",
    "        )\n",
    "        sampled_z = self.mean + gaussian_noise * torch.exp(self.log_std).to(\n",
    "            device\n",
    "        )\n",
    "        return sampled_z\n",
    "\n",
    "    def decoder(self, z):\n",
    "        adj_rec = torch.sigmoid(torch.matmul(z, z.t()))\n",
    "        return adj_rec\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        z = self.encoder(g, features)\n",
    "        adj_rec = self.decoder(z)\n",
    "        return adj_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONNECTIVITY_MATRIX_SHAPE:  (360, 490)\n",
      "FC_MATRIX_SHAPE: (1, 360, 360)\n",
      "GRAPHS_SHAPE: (1, 360, 360)\n",
      "FC_MATRIX_SHAPE_NEW: (360, 360)\n"
     ]
    }
   ],
   "source": [
    "path_conn = '../data/hcp/raw/100206_0.npy'\n",
    "path_brain_region = '../data/brain_regions.csv'\n",
    "\n",
    "# Load the connectivity matrix\n",
    "scan = np.load(path_conn)[:, :490]\n",
    "print('CONNECTIVITY_MATRIX_SHAPE: ', scan.shape)\n",
    "\n",
    "fc_matrices = create_fc_matrices(scan, 490, 1)\n",
    "print('FC_MATRIX_SHAPE:', np.array(fc_matrices).shape)\n",
    "\n",
    "graphs = [threshold_fc_matrix(fc) for fc in fc_matrices]\n",
    "print(\"GRAPHS_SHAPE:\" ,np.array(graphs).shape)\n",
    "\n",
    "# fc_matrices = np.array(fc_matrices)[0]\n",
    "fc_matrices_tr = sp.csr_matrix(graphs[0])\n",
    "fc_matrices_last = fc_matrices_tr.astype(int)\n",
    "print(\"FC_MATRIX_SHAPE_NEW:\" , fc_matrices_last.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "adj_orig = fc_matrices_last\n",
    "print(type(fc_matrices_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[  0,   3],\n",
      "       [  0,   4],\n",
      "       [  0,   5],\n",
      "       ...,\n",
      "       [359, 264],\n",
      "       [359, 349],\n",
      "       [359, 358]], dtype=int32), array([1, 1, 1, ..., 1, 1, 1]), (360, 360))\n",
      "(6462, 2)\n"
     ]
    }
   ],
   "source": [
    "print(sparse_to_tuple(fc_matrices_last))\n",
    "print(sparse_to_tuple(fc_matrices_last)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    adj_train,\n",
    "    train_edges,\n",
    "    val_edges,\n",
    "    val_edges_false,\n",
    "    test_edges,\n",
    "    test_edges_false,\n",
    ") = mask_test_edges(fc_matrices_last)\n",
    "adj = adj_train        # remember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5494, 2)\n",
      "(2747, 2)\n",
      "(161, 2)\n",
      "(323, 2)\n",
      "161\n",
      "323\n"
     ]
    }
   ],
   "source": [
    "print(sparse_to_tuple(adj_train)[0].shape) # --> 5494 = 2747*2 (nodi) \n",
    "print(train_edges.shape)\n",
    "print(val_edges.shape)\n",
    "print(test_edges.shape)\n",
    "print(len(val_edges_false))\n",
    "print(len(test_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some preprocessing\n",
    "adj_normalization, adj_norm = preprocess_graph(adj)\n",
    "\n",
    "# Create model\n",
    "graph = dgl.from_scipy(adj_normalization)\n",
    "graph.remove_self_loop()\n",
    "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "norm = (\n",
    "    adj.shape[0]\n",
    "    * adj.shape[0]\n",
    "    / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    ")\n",
    "\n",
    "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "adj_label = sparse_to_tuple(adj_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=360, num_edges=5854,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5854, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_label[0].shape       # --> 5854 = 5494 + 360 (self loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([360, 360])\n"
     ]
    }
   ],
   "source": [
    "adj_norm = torch.sparse.FloatTensor(       # think never used \n",
    "    torch.LongTensor(adj_norm[0].T),\n",
    "    torch.FloatTensor(adj_norm[1]),\n",
    "    torch.Size(adj_norm[2]),\n",
    ")\n",
    "adj_label = torch.sparse.FloatTensor(\n",
    "    torch.LongTensor(adj_label[0].T),\n",
    "    torch.FloatTensor(adj_label[1]),\n",
    "    torch.Size(adj_label[2]),\n",
    ")\n",
    "features = sparse_to_tuple(fc_matrices_last.tocoo())   # --> (6462, 2)\n",
    "features = torch.sparse.FloatTensor(\n",
    "    torch.LongTensor(features[0].T),\n",
    "    torch.FloatTensor(features[1]),\n",
    "    torch.Size(features[2]),\n",
    ")\n",
    "\n",
    "weight_mask = adj_label.to_dense().view(-1) == 1\n",
    "weight_tensor = torch.ones(weight_mask.size(0))\n",
    "weight_tensor[weight_mask] = pos_weight\n",
    "\n",
    "features = features.to_dense()\n",
    "print(features.shape)\n",
    "in_dim = features.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 12608\n"
     ]
    }
   ],
   "source": [
    "vgae_model = VGAEModel(in_dim, 32, 16)\n",
    "# create training component\n",
    "optimizer = torch.optim.Adam(vgae_model.parameters(), lr=0.01)\n",
    "print(\n",
    "    \"Total Parameters:\",\n",
    "    sum([p.nelement() for p in vgae_model.parameters()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.74276 train_acc= 0.50020 val_roc= 0.47537 val_ap= 0.50637 time= 0.06780\n",
      "Epoch: 0002 train_loss= 1.43413 train_acc= 0.48815 val_roc= 0.47691 val_ap= 0.48982 time= 0.04073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 train_loss= 1.19284 train_acc= 0.41005 val_roc= 0.64519 val_ap= 0.62243 time= 0.03650\n",
      "Epoch: 0004 train_loss= 1.09450 train_acc= 0.38585 val_roc= 0.71672 val_ap= 0.69726 time= 0.02981\n",
      "Epoch: 0005 train_loss= 1.04455 train_acc= 0.34367 val_roc= 0.72042 val_ap= 0.70504 time= 0.02600\n",
      "Epoch: 0006 train_loss= 0.94131 train_acc= 0.36625 val_roc= 0.77030 val_ap= 0.74616 time= 0.02492\n",
      "Epoch: 0007 train_loss= 0.84473 train_acc= 0.38779 val_roc= 0.72200 val_ap= 0.64482 time= 0.02413\n",
      "Epoch: 0008 train_loss= 0.83090 train_acc= 0.37301 val_roc= 0.63458 val_ap= 0.57646 time= 0.02458\n",
      "Epoch: 0009 train_loss= 0.75811 train_acc= 0.41574 val_roc= 0.70522 val_ap= 0.60810 time= 0.02367\n",
      "Epoch: 0010 train_loss= 0.72408 train_acc= 0.42213 val_roc= 0.69986 val_ap= 0.61617 time= 0.02376\n",
      "Epoch: 0011 train_loss= 0.72251 train_acc= 0.40196 val_roc= 0.75483 val_ap= 0.66141 time= 0.02319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0012 train_loss= 0.68465 train_acc= 0.43065 val_roc= 0.77115 val_ap= 0.70391 time= 0.02355\n",
      "Epoch: 0013 train_loss= 0.64971 train_acc= 0.46176 val_roc= 0.81752 val_ap= 0.76515 time= 0.02302\n",
      "Epoch: 0014 train_loss= 0.61958 train_acc= 0.50318 val_roc= 0.81008 val_ap= 0.77239 time= 0.02203\n",
      "Epoch: 0015 train_loss= 0.60351 train_acc= 0.52537 val_roc= 0.84025 val_ap= 0.80602 time= 0.02273\n",
      "Epoch: 0016 train_loss= 0.59404 train_acc= 0.53113 val_roc= 0.86825 val_ap= 0.85213 time= 0.02218\n",
      "Epoch: 0017 train_loss= 0.60079 train_acc= 0.51975 val_roc= 0.86088 val_ap= 0.83666 time= 0.02250\n",
      "Epoch: 0018 train_loss= 0.60594 train_acc= 0.51032 val_roc= 0.89877 val_ap= 0.90314 time= 0.02218\n",
      "Epoch: 0019 train_loss= 0.59436 train_acc= 0.53150 val_roc= 0.87639 val_ap= 0.86395 time= 0.02297\n",
      "Epoch: 0020 train_loss= 0.59816 train_acc= 0.53134 val_roc= 0.88534 val_ap= 0.87026 time= 0.02196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0021 train_loss= 0.58234 train_acc= 0.55313 val_roc= 0.87686 val_ap= 0.88528 time= 0.02209\n",
      "Epoch: 0022 train_loss= 0.57587 train_acc= 0.54628 val_roc= 0.89588 val_ap= 0.89904 time= 0.02185\n",
      "Epoch: 0023 train_loss= 0.56475 train_acc= 0.55216 val_roc= 0.91300 val_ap= 0.89582 time= 0.02173\n",
      "Epoch: 0024 train_loss= 0.55909 train_acc= 0.55019 val_roc= 0.90579 val_ap= 0.90555 time= 0.02152\n",
      "Epoch: 0025 train_loss= 0.55581 train_acc= 0.54949 val_roc= 0.88268 val_ap= 0.88637 time= 0.02166\n",
      "Epoch: 0026 train_loss= 0.55806 train_acc= 0.54319 val_roc= 0.89970 val_ap= 0.88137 time= 0.02182\n",
      "Epoch: 0027 train_loss= 0.55217 train_acc= 0.55802 val_roc= 0.88415 val_ap= 0.86474 time= 0.02147\n",
      "Epoch: 0028 train_loss= 0.55279 train_acc= 0.54369 val_roc= 0.89464 val_ap= 0.87258 time= 0.02184\n",
      "Epoch: 0029 train_loss= 0.54979 train_acc= 0.54722 val_roc= 0.91065 val_ap= 0.89415 time= 0.02219\n",
      "Epoch: 0030 train_loss= 0.54633 train_acc= 0.54620 val_roc= 0.90895 val_ap= 0.90657 time= 0.02174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0031 train_loss= 0.54633 train_acc= 0.53519 val_roc= 0.91200 val_ap= 0.88375 time= 0.02209\n",
      "Epoch: 0032 train_loss= 0.54275 train_acc= 0.55069 val_roc= 0.89696 val_ap= 0.87117 time= 0.02173\n",
      "Epoch: 0033 train_loss= 0.54083 train_acc= 0.55637 val_roc= 0.92134 val_ap= 0.92116 time= 0.02151\n",
      "Epoch: 0034 train_loss= 0.53497 train_acc= 0.57128 val_roc= 0.91520 val_ap= 0.90854 time= 0.02150\n",
      "Epoch: 0035 train_loss= 0.53221 train_acc= 0.57179 val_roc= 0.92535 val_ap= 0.91741 time= 0.02231\n",
      "Epoch: 0036 train_loss= 0.52307 train_acc= 0.57687 val_roc= 0.93650 val_ap= 0.93633 time= 0.02196\n",
      "Epoch: 0037 train_loss= 0.52320 train_acc= 0.57454 val_roc= 0.93218 val_ap= 0.93121 time= 0.02216\n",
      "Epoch: 0038 train_loss= 0.52412 train_acc= 0.56718 val_roc= 0.91883 val_ap= 0.91406 time= 0.02180\n",
      "Epoch: 0039 train_loss= 0.52666 train_acc= 0.57410 val_roc= 0.91574 val_ap= 0.91388 time= 0.02177\n",
      "Epoch: 0040 train_loss= 0.52126 train_acc= 0.57233 val_roc= 0.93349 val_ap= 0.93389 time= 0.02181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0041 train_loss= 0.51985 train_acc= 0.57674 val_roc= 0.92080 val_ap= 0.92261 time= 0.02218\n",
      "Epoch: 0042 train_loss= 0.51559 train_acc= 0.57844 val_roc= 0.93133 val_ap= 0.93534 time= 0.02185\n",
      "Epoch: 0043 train_loss= 0.51327 train_acc= 0.57850 val_roc= 0.92971 val_ap= 0.92951 time= 0.02156\n",
      "Epoch: 0044 train_loss= 0.51413 train_acc= 0.57421 val_roc= 0.92157 val_ap= 0.92235 time= 0.02147\n",
      "Epoch: 0045 train_loss= 0.51270 train_acc= 0.57151 val_roc= 0.93272 val_ap= 0.93023 time= 0.02209\n",
      "Epoch: 0046 train_loss= 0.51083 train_acc= 0.58113 val_roc= 0.94248 val_ap= 0.93536 time= 0.02190\n",
      "Epoch: 0047 train_loss= 0.51004 train_acc= 0.57829 val_roc= 0.90668 val_ap= 0.90355 time= 0.02266\n",
      "Epoch: 0048 train_loss= 0.51183 train_acc= 0.57434 val_roc= 0.92192 val_ap= 0.92876 time= 0.02232\n",
      "Epoch: 0049 train_loss= 0.51013 train_acc= 0.57398 val_roc= 0.93611 val_ap= 0.92789 time= 0.02218\n",
      "Epoch: 0050 train_loss= 0.50921 train_acc= 0.57926 val_roc= 0.92512 val_ap= 0.92012 time= 0.02234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0051 train_loss= 0.50612 train_acc= 0.57907 val_roc= 0.93087 val_ap= 0.93280 time= 0.02313\n",
      "Epoch: 0052 train_loss= 0.50771 train_acc= 0.57520 val_roc= 0.91729 val_ap= 0.91969 time= 0.02233\n",
      "Epoch: 0053 train_loss= 0.50496 train_acc= 0.57708 val_roc= 0.93592 val_ap= 0.94125 time= 0.02172\n",
      "Epoch: 0054 train_loss= 0.50774 train_acc= 0.57380 val_roc= 0.92805 val_ap= 0.93234 time= 0.02191\n",
      "Epoch: 0055 train_loss= 0.50405 train_acc= 0.57907 val_roc= 0.93507 val_ap= 0.93602 time= 0.02367\n",
      "Epoch: 0056 train_loss= 0.50506 train_acc= 0.57826 val_roc= 0.94603 val_ap= 0.94647 time= 0.02304\n",
      "Epoch: 0057 train_loss= 0.50248 train_acc= 0.57665 val_roc= 0.92674 val_ap= 0.92549 time= 0.02192\n",
      "Epoch: 0058 train_loss= 0.50356 train_acc= 0.58261 val_roc= 0.93654 val_ap= 0.92932 time= 0.02341\n",
      "Epoch: 0059 train_loss= 0.50029 train_acc= 0.57815 val_roc= 0.93114 val_ap= 0.94111 time= 0.02222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0060 train_loss= 0.50073 train_acc= 0.58594 val_roc= 0.93052 val_ap= 0.92157 time= 0.02259\n",
      "Epoch: 0061 train_loss= 0.49853 train_acc= 0.58579 val_roc= 0.93118 val_ap= 0.92111 time= 0.03003\n",
      "Epoch: 0062 train_loss= 0.49780 train_acc= 0.58455 val_roc= 0.92998 val_ap= 0.92589 time= 0.02771\n",
      "Epoch: 0063 train_loss= 0.49915 train_acc= 0.59139 val_roc= 0.93341 val_ap= 0.92581 time= 0.02667\n",
      "Epoch: 0064 train_loss= 0.49584 train_acc= 0.58515 val_roc= 0.93253 val_ap= 0.92816 time= 0.02244\n",
      "Epoch: 0065 train_loss= 0.49931 train_acc= 0.58647 val_roc= 0.91856 val_ap= 0.91811 time= 0.02230\n",
      "Epoch: 0066 train_loss= 0.49475 train_acc= 0.59085 val_roc= 0.93665 val_ap= 0.94391 time= 0.02252\n",
      "Epoch: 0067 train_loss= 0.49652 train_acc= 0.58684 val_roc= 0.93758 val_ap= 0.92822 time= 0.02217\n",
      "Epoch: 0068 train_loss= 0.49557 train_acc= 0.58474 val_roc= 0.93457 val_ap= 0.93624 time= 0.02198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0069 train_loss= 0.49360 train_acc= 0.58898 val_roc= 0.93453 val_ap= 0.94065 time= 0.02220\n",
      "Epoch: 0070 train_loss= 0.49397 train_acc= 0.58494 val_roc= 0.95560 val_ap= 0.96119 time= 0.02230\n",
      "Epoch: 0071 train_loss= 0.49380 train_acc= 0.58636 val_roc= 0.94379 val_ap= 0.92209 time= 0.02154\n",
      "Epoch: 0072 train_loss= 0.49272 train_acc= 0.58531 val_roc= 0.94572 val_ap= 0.94932 time= 0.02159\n",
      "Epoch: 0073 train_loss= 0.49314 train_acc= 0.58944 val_roc= 0.93438 val_ap= 0.94061 time= 0.02166\n",
      "Epoch: 0074 train_loss= 0.49256 train_acc= 0.58764 val_roc= 0.94016 val_ap= 0.94208 time= 0.02219\n",
      "Epoch: 0075 train_loss= 0.49282 train_acc= 0.58792 val_roc= 0.93249 val_ap= 0.93328 time= 0.02160\n",
      "Epoch: 0076 train_loss= 0.49410 train_acc= 0.59017 val_roc= 0.92820 val_ap= 0.91546 time= 0.02163\n",
      "Epoch: 0077 train_loss= 0.49285 train_acc= 0.58653 val_roc= 0.94734 val_ap= 0.95077 time= 0.02209\n",
      "Epoch: 0078 train_loss= 0.49204 train_acc= 0.58898 val_roc= 0.93692 val_ap= 0.93348 time= 0.02176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0079 train_loss= 0.49076 train_acc= 0.58972 val_roc= 0.92817 val_ap= 0.92887 time= 0.02215\n",
      "Epoch: 0080 train_loss= 0.49105 train_acc= 0.58759 val_roc= 0.94638 val_ap= 0.94866 time= 0.02184\n",
      "Epoch: 0081 train_loss= 0.49014 train_acc= 0.58500 val_roc= 0.93098 val_ap= 0.94039 time= 0.02140\n",
      "Epoch: 0082 train_loss= 0.49247 train_acc= 0.58485 val_roc= 0.93087 val_ap= 0.92058 time= 0.02204\n",
      "Epoch: 0083 train_loss= 0.48964 train_acc= 0.58650 val_roc= 0.94136 val_ap= 0.94296 time= 0.02197\n",
      "Epoch: 0084 train_loss= 0.48990 train_acc= 0.58846 val_roc= 0.94028 val_ap= 0.94665 time= 0.02187\n",
      "Epoch: 0085 train_loss= 0.48903 train_acc= 0.58372 val_roc= 0.93480 val_ap= 0.94367 time= 0.02204\n",
      "Epoch: 0086 train_loss= 0.49092 train_acc= 0.58617 val_roc= 0.93480 val_ap= 0.93879 time= 0.02199\n",
      "Epoch: 0087 train_loss= 0.48970 train_acc= 0.58492 val_roc= 0.93635 val_ap= 0.93183 time= 0.02175\n",
      "Epoch: 0088 train_loss= 0.48812 train_acc= 0.58498 val_roc= 0.93681 val_ap= 0.94292 time= 0.02207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0089 train_loss= 0.49064 train_acc= 0.58380 val_roc= 0.94422 val_ap= 0.94195 time= 0.02196\n",
      "Epoch: 0090 train_loss= 0.48906 train_acc= 0.58343 val_roc= 0.94298 val_ap= 0.94801 time= 0.02179\n",
      "Epoch: 0091 train_loss= 0.48989 train_acc= 0.58606 val_roc= 0.94765 val_ap= 0.95371 time= 0.02171\n",
      "Epoch: 0092 train_loss= 0.48689 train_acc= 0.58935 val_roc= 0.94645 val_ap= 0.94159 time= 0.02214\n",
      "Epoch: 0093 train_loss= 0.48678 train_acc= 0.58705 val_roc= 0.95093 val_ap= 0.95477 time= 0.02220\n",
      "Epoch: 0094 train_loss= 0.48653 train_acc= 0.58941 val_roc= 0.95359 val_ap= 0.95503 time= 0.02170\n",
      "Epoch: 0095 train_loss= 0.48755 train_acc= 0.58667 val_roc= 0.94719 val_ap= 0.94807 time= 0.02165\n",
      "Epoch: 0096 train_loss= 0.48540 train_acc= 0.58878 val_roc= 0.93503 val_ap= 0.94382 time= 0.02203\n",
      "Epoch: 0097 train_loss= 0.48600 train_acc= 0.59310 val_roc= 0.95000 val_ap= 0.95197 time= 0.02165\n",
      "Epoch: 0098 train_loss= 0.48517 train_acc= 0.58694 val_roc= 0.94680 val_ap= 0.94723 time= 0.02183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0099 train_loss= 0.48583 train_acc= 0.59137 val_roc= 0.94217 val_ap= 0.94462 time= 0.02159\n",
      "Epoch: 0100 train_loss= 0.48703 train_acc= 0.58844 val_roc= 0.93615 val_ap= 0.92096 time= 0.02190\n",
      "Epoch: 0101 train_loss= 0.48422 train_acc= 0.58903 val_roc= 0.95679 val_ap= 0.95202 time= 0.02197\n",
      "Epoch: 0102 train_loss= 0.48730 train_acc= 0.58645 val_roc= 0.94178 val_ap= 0.92774 time= 0.02154\n",
      "Epoch: 0103 train_loss= 0.48459 train_acc= 0.58769 val_roc= 0.95344 val_ap= 0.93765 time= 0.02193\n",
      "Epoch: 0104 train_loss= 0.48471 train_acc= 0.58313 val_roc= 0.94549 val_ap= 0.93756 time= 0.02177\n",
      "Epoch: 0105 train_loss= 0.48536 train_acc= 0.58869 val_roc= 0.94888 val_ap= 0.95664 time= 0.02198\n",
      "Epoch: 0106 train_loss= 0.48654 train_acc= 0.58698 val_roc= 0.94927 val_ap= 0.94364 time= 0.02309\n",
      "Epoch: 0107 train_loss= 0.48631 train_acc= 0.58600 val_roc= 0.93816 val_ap= 0.94140 time= 0.02280\n",
      "Epoch: 0108 train_loss= 0.48342 train_acc= 0.59358 val_roc= 0.94028 val_ap= 0.92506 time= 0.02193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0109 train_loss= 0.48265 train_acc= 0.58508 val_roc= 0.95506 val_ap= 0.95686 time= 0.02227\n",
      "Epoch: 0110 train_loss= 0.48433 train_acc= 0.58895 val_roc= 0.94360 val_ap= 0.93244 time= 0.02165\n",
      "Epoch: 0111 train_loss= 0.48293 train_acc= 0.58875 val_roc= 0.95305 val_ap= 0.95275 time= 0.02162\n",
      "Epoch: 0112 train_loss= 0.48557 train_acc= 0.59113 val_roc= 0.93596 val_ap= 0.93688 time= 0.02200\n",
      "Epoch: 0113 train_loss= 0.48341 train_acc= 0.59363 val_roc= 0.95760 val_ap= 0.95144 time= 0.02151\n",
      "Epoch: 0114 train_loss= 0.48490 train_acc= 0.59065 val_roc= 0.96111 val_ap= 0.96003 time= 0.02179\n",
      "Epoch: 0115 train_loss= 0.48451 train_acc= 0.58883 val_roc= 0.93588 val_ap= 0.93896 time= 0.02202\n",
      "Epoch: 0116 train_loss= 0.48319 train_acc= 0.58994 val_roc= 0.95428 val_ap= 0.94938 time= 0.02161\n",
      "Epoch: 0117 train_loss= 0.48160 train_acc= 0.58784 val_roc= 0.94965 val_ap= 0.94916 time= 0.02177\n",
      "Epoch: 0118 train_loss= 0.48287 train_acc= 0.59231 val_roc= 0.95548 val_ap= 0.95391 time= 0.02171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0119 train_loss= 0.48219 train_acc= 0.59250 val_roc= 0.95336 val_ap= 0.95536 time= 0.02312\n",
      "Epoch: 0120 train_loss= 0.48081 train_acc= 0.59213 val_roc= 0.95502 val_ap= 0.94474 time= 0.02196\n",
      "Epoch: 0121 train_loss= 0.48260 train_acc= 0.59443 val_roc= 0.94209 val_ap= 0.93804 time= 0.02144\n",
      "Epoch: 0122 train_loss= 0.48058 train_acc= 0.59497 val_roc= 0.93526 val_ap= 0.92630 time= 0.02164\n",
      "Epoch: 0123 train_loss= 0.48004 train_acc= 0.59221 val_roc= 0.95860 val_ap= 0.95917 time= 0.02221\n",
      "Epoch: 0124 train_loss= 0.48240 train_acc= 0.58759 val_roc= 0.95845 val_ap= 0.95264 time= 0.02177\n",
      "Epoch: 0125 train_loss= 0.48326 train_acc= 0.59127 val_roc= 0.95417 val_ap= 0.95980 time= 0.02150\n",
      "Epoch: 0126 train_loss= 0.47921 train_acc= 0.59082 val_roc= 0.95266 val_ap= 0.95324 time= 0.02191\n",
      "Epoch: 0127 train_loss= 0.47924 train_acc= 0.59414 val_roc= 0.95131 val_ap= 0.94743 time= 0.02166\n",
      "Epoch: 0128 train_loss= 0.48149 train_acc= 0.59370 val_roc= 0.95710 val_ap= 0.95895 time= 0.02181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0129 train_loss= 0.48031 train_acc= 0.59390 val_roc= 0.93916 val_ap= 0.94013 time= 0.02428\n",
      "Epoch: 0130 train_loss= 0.47974 train_acc= 0.59576 val_roc= 0.95417 val_ap= 0.95672 time= 0.02363\n",
      "Epoch: 0131 train_loss= 0.47947 train_acc= 0.59593 val_roc= 0.95367 val_ap= 0.95788 time= 0.02337\n",
      "Epoch: 0132 train_loss= 0.48005 train_acc= 0.59051 val_roc= 0.95239 val_ap= 0.94962 time= 0.02415\n",
      "Epoch: 0133 train_loss= 0.47670 train_acc= 0.59252 val_roc= 0.93727 val_ap= 0.91968 time= 0.02342\n",
      "Epoch: 0134 train_loss= 0.48360 train_acc= 0.59293 val_roc= 0.94572 val_ap= 0.94166 time= 0.02367\n",
      "Epoch: 0135 train_loss= 0.47872 train_acc= 0.59119 val_roc= 0.94533 val_ap= 0.94121 time= 0.02346\n",
      "Epoch: 0136 train_loss= 0.47911 train_acc= 0.59355 val_roc= 0.94526 val_ap= 0.94681 time= 0.02479\n",
      "Epoch: 0137 train_loss= 0.47962 train_acc= 0.59248 val_roc= 0.94221 val_ap= 0.94184 time= 0.02358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0138 train_loss= 0.48030 train_acc= 0.59082 val_roc= 0.94950 val_ap= 0.94758 time= 0.02431\n",
      "Epoch: 0139 train_loss= 0.47954 train_acc= 0.58977 val_roc= 0.94873 val_ap= 0.94016 time= 0.02338\n",
      "Epoch: 0140 train_loss= 0.47957 train_acc= 0.58798 val_roc= 0.95170 val_ap= 0.95115 time= 0.02329\n",
      "Epoch: 0141 train_loss= 0.48032 train_acc= 0.59247 val_roc= 0.94958 val_ap= 0.94707 time= 0.02418\n",
      "Epoch: 0142 train_loss= 0.48111 train_acc= 0.59162 val_roc= 0.95201 val_ap= 0.94171 time= 0.02366\n",
      "Epoch: 0143 train_loss= 0.47925 train_acc= 0.59255 val_roc= 0.94217 val_ap= 0.94032 time= 0.02444\n",
      "Epoch: 0144 train_loss= 0.47836 train_acc= 0.59330 val_roc= 0.94549 val_ap= 0.93942 time= 0.02365\n",
      "Epoch: 0145 train_loss= 0.47995 train_acc= 0.59100 val_roc= 0.94391 val_ap= 0.94387 time= 0.02485\n",
      "Epoch: 0146 train_loss= 0.47901 train_acc= 0.59231 val_roc= 0.95151 val_ap= 0.94896 time= 0.02377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0147 train_loss= 0.47929 train_acc= 0.59167 val_roc= 0.94190 val_ap= 0.94123 time= 0.02439\n",
      "Epoch: 0148 train_loss= 0.47786 train_acc= 0.59153 val_roc= 0.95533 val_ap= 0.95187 time= 0.02362\n",
      "Epoch: 0149 train_loss= 0.48031 train_acc= 0.58478 val_roc= 0.95436 val_ap= 0.94835 time= 0.02345\n",
      "Epoch: 0150 train_loss= 0.47733 train_acc= 0.58934 val_roc= 0.94676 val_ap= 0.94636 time= 0.02449\n",
      "Epoch: 0151 train_loss= 0.47757 train_acc= 0.59113 val_roc= 0.96289 val_ap= 0.95894 time= 0.02373\n",
      "Epoch: 0152 train_loss= 0.47839 train_acc= 0.59051 val_roc= 0.95633 val_ap= 0.95975 time= 0.02467\n",
      "Epoch: 0153 train_loss= 0.47896 train_acc= 0.59065 val_roc= 0.95104 val_ap= 0.95437 time= 0.02354\n",
      "Epoch: 0154 train_loss= 0.47684 train_acc= 0.59093 val_roc= 0.95768 val_ap= 0.95534 time= 0.02467\n",
      "Epoch: 0155 train_loss= 0.47863 train_acc= 0.59150 val_roc= 0.94313 val_ap= 0.93532 time= 0.02392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0156 train_loss= 0.47563 train_acc= 0.58758 val_roc= 0.95290 val_ap= 0.95190 time= 0.02477\n",
      "Epoch: 0157 train_loss= 0.47526 train_acc= 0.59427 val_roc= 0.94155 val_ap= 0.94767 time= 0.02422\n",
      "Epoch: 0158 train_loss= 0.47793 train_acc= 0.58872 val_roc= 0.95814 val_ap= 0.95864 time= 0.02329\n",
      "Epoch: 0159 train_loss= 0.47812 train_acc= 0.59056 val_roc= 0.95571 val_ap= 0.94512 time= 0.02499\n",
      "Epoch: 0160 train_loss= 0.47663 train_acc= 0.59145 val_roc= 0.94580 val_ap= 0.94904 time= 0.02398\n",
      "Epoch: 0161 train_loss= 0.47625 train_acc= 0.59535 val_roc= 0.94449 val_ap= 0.94563 time= 0.02535\n",
      "Epoch: 0162 train_loss= 0.47731 train_acc= 0.59465 val_roc= 0.95521 val_ap= 0.95592 time= 0.02437\n",
      "Epoch: 0163 train_loss= 0.47570 train_acc= 0.59304 val_roc= 0.96790 val_ap= 0.96560 time= 0.02538\n",
      "Epoch: 0164 train_loss= 0.47624 train_acc= 0.58965 val_roc= 0.95853 val_ap= 0.96006 time= 0.02558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0165 train_loss= 0.47582 train_acc= 0.58733 val_roc= 0.95359 val_ap= 0.94194 time= 0.02612\n",
      "Epoch: 0166 train_loss= 0.47649 train_acc= 0.58932 val_roc= 0.95023 val_ap= 0.94473 time= 0.02590\n",
      "Epoch: 0167 train_loss= 0.47540 train_acc= 0.58968 val_roc= 0.95544 val_ap= 0.95232 time= 0.02626\n",
      "Epoch: 0168 train_loss= 0.47656 train_acc= 0.59654 val_roc= 0.94915 val_ap= 0.94369 time= 0.02620\n",
      "Epoch: 0169 train_loss= 0.47611 train_acc= 0.58955 val_roc= 0.96408 val_ap= 0.96042 time= 0.02657\n",
      "Epoch: 0170 train_loss= 0.47561 train_acc= 0.59392 val_roc= 0.95660 val_ap= 0.94459 time= 0.02584\n",
      "Epoch: 0171 train_loss= 0.47513 train_acc= 0.59404 val_roc= 0.94591 val_ap= 0.94824 time= 0.02642\n",
      "Epoch: 0172 train_loss= 0.47544 train_acc= 0.59142 val_roc= 0.95089 val_ap= 0.95322 time= 0.02560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0173 train_loss= 0.47672 train_acc= 0.59082 val_roc= 0.95911 val_ap= 0.95907 time= 0.02524\n",
      "Epoch: 0174 train_loss= 0.47646 train_acc= 0.59313 val_roc= 0.94653 val_ap= 0.94343 time= 0.02381\n",
      "Epoch: 0175 train_loss= 0.47652 train_acc= 0.59253 val_roc= 0.95629 val_ap= 0.95187 time= 0.02459\n",
      "Epoch: 0176 train_loss= 0.47532 train_acc= 0.58833 val_roc= 0.95749 val_ap= 0.95740 time= 0.02408\n",
      "Epoch: 0177 train_loss= 0.47587 train_acc= 0.58875 val_roc= 0.95050 val_ap= 0.94473 time= 0.02354\n",
      "Epoch: 0178 train_loss= 0.47706 train_acc= 0.59134 val_roc= 0.94869 val_ap= 0.94872 time= 0.02459\n",
      "Epoch: 0179 train_loss= 0.47296 train_acc= 0.59261 val_roc= 0.95888 val_ap= 0.94463 time= 0.02401\n",
      "Epoch: 0180 train_loss= 0.47350 train_acc= 0.59321 val_roc= 0.94811 val_ap= 0.95346 time= 0.02440\n",
      "Epoch: 0181 train_loss= 0.47559 train_acc= 0.59335 val_roc= 0.94117 val_ap= 0.94516 time= 0.02416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0182 train_loss= 0.47391 train_acc= 0.59461 val_roc= 0.95220 val_ap= 0.94776 time= 0.02445\n",
      "Epoch: 0183 train_loss= 0.47349 train_acc= 0.59481 val_roc= 0.94487 val_ap= 0.94173 time= 0.02406\n",
      "Epoch: 0184 train_loss= 0.47335 train_acc= 0.59583 val_roc= 0.95915 val_ap= 0.95757 time= 0.02586\n",
      "Epoch: 0185 train_loss= 0.47327 train_acc= 0.59202 val_roc= 0.95691 val_ap= 0.96394 time= 0.02431\n",
      "Epoch: 0186 train_loss= 0.47323 train_acc= 0.59495 val_roc= 0.95525 val_ap= 0.94855 time= 0.02364\n",
      "Epoch: 0187 train_loss= 0.47353 train_acc= 0.59642 val_roc= 0.95239 val_ap= 0.94496 time= 0.02529\n",
      "Epoch: 0188 train_loss= 0.47323 train_acc= 0.59511 val_roc= 0.95826 val_ap= 0.96105 time= 0.02454\n",
      "Epoch: 0189 train_loss= 0.47307 train_acc= 0.60215 val_roc= 0.95691 val_ap= 0.95432 time= 0.02417\n",
      "Epoch: 0190 train_loss= 0.47373 train_acc= 0.59785 val_roc= 0.95961 val_ap= 0.95766 time= 0.02454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0191 train_loss= 0.47302 train_acc= 0.59657 val_roc= 0.95143 val_ap= 0.95424 time= 0.02399\n",
      "Epoch: 0192 train_loss= 0.47218 train_acc= 0.59486 val_roc= 0.94472 val_ap= 0.93390 time= 0.02464\n",
      "Epoch: 0193 train_loss= 0.46990 train_acc= 0.59853 val_roc= 0.95556 val_ap= 0.95285 time= 0.02530\n",
      "Epoch: 0194 train_loss= 0.47258 train_acc= 0.59954 val_roc= 0.94884 val_ap= 0.94771 time= 0.02464\n",
      "Epoch: 0195 train_loss= 0.47204 train_acc= 0.59688 val_roc= 0.95949 val_ap= 0.95862 time= 0.02417\n",
      "Epoch: 0196 train_loss= 0.47292 train_acc= 0.59636 val_roc= 0.96551 val_ap= 0.96913 time= 0.02498\n",
      "Epoch: 0197 train_loss= 0.47134 train_acc= 0.59645 val_roc= 0.96131 val_ap= 0.96390 time= 0.02421\n",
      "Epoch: 0198 train_loss= 0.47284 train_acc= 0.59934 val_roc= 0.95039 val_ap= 0.94749 time= 0.02460\n",
      "Epoch: 0199 train_loss= 0.46975 train_acc= 0.59989 val_roc= 0.95779 val_ap= 0.95720 time= 0.02420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/matteoc/miniconda3/envs/dbgdgm/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0200 train_loss= 0.47147 train_acc= 0.59633 val_roc= 0.96192 val_ap= 0.96355 time= 0.02355\n",
      "End of training! test_roc= 0.96718 test_ap= 0.96686\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "\n",
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        # print(e)\n",
    "        # print(adj_rec[e[0], e[1]])\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score\n",
    "\n",
    "def get_acc(adj_rec, adj_label):\n",
    "    labels_all = adj_label.to_dense().view(-1).long()\n",
    "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
    "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
    "    return accuracy, labels_all, preds_all\n",
    "\n",
    "for epoch in range(200):\n",
    "    t = time.time()\n",
    "\n",
    "    # Training and validation using a full graph\n",
    "    vgae_model.train()\n",
    "\n",
    "    logits = vgae_model.forward(graph, features)\n",
    "\n",
    "    # compute loss\n",
    "    loss = norm * F.binary_cross_entropy(\n",
    "        logits.view(-1), adj_label.to_dense().view(-1), weight=weight_tensor\n",
    "    )\n",
    "    kl_divergence = (\n",
    "        0.5\n",
    "        / logits.size(0)\n",
    "        * (\n",
    "            1\n",
    "            + 2 * vgae_model.log_std\n",
    "            - vgae_model.mean**2\n",
    "            - torch.exp(vgae_model.log_std) ** 2\n",
    "        )\n",
    "        .sum(1)\n",
    "        .mean()\n",
    "    )\n",
    "    loss -= kl_divergence\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_acc, true_all, preds_all = get_acc(logits, adj_label)\n",
    "\n",
    "    val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "\n",
    "    # Print out performance\n",
    "    print(\n",
    "        \"Epoch:\",\n",
    "        \"%04d\" % (epoch + 1),\n",
    "        \"train_loss=\",\n",
    "        \"{:.5f}\".format(loss.item()),\n",
    "        \"train_acc=\",\n",
    "        \"{:.5f}\".format(train_acc),\n",
    "        \"val_roc=\",\n",
    "        \"{:.5f}\".format(val_roc),\n",
    "        \"val_ap=\",\n",
    "        \"{:.5f}\".format(val_ap),\n",
    "        \"time=\",\n",
    "        \"{:.5f}\".format(time.time() - t),\n",
    "    )\n",
    "\n",
    "test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "print(\n",
    "    \"End of training!\",\n",
    "    \"test_roc=\",\n",
    "    \"{:.5f}\".format(test_roc),\n",
    "    \"test_ap=\",\n",
    "    \"{:.5f}\".format(test_ap),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbgdgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
